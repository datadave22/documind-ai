# ðŸ“˜ DocuMind AI

**Productionâ€‘Ready Retrievalâ€‘Augmented Generation (RAG) Library**  
A modular, reusable TypeScript package that powers semantic search and AIâ€‘driven question answering over private documents.

---

## ðŸš€ What Is DocuMind AI?

DocuMind AI is a standalone RAG pipeline designed for **building documentâ€‘aware AI applications**. It combines:

- Embedding generation using OpenAI
- Vector retrieval using Qdrant
- Prompt templates with citation support
- Streaming LLM responses with costâ€‘aware model selection

It is fully typeâ€‘safe, compiled with TypeScript, and suitable for deployment in backend services, microservices, or as an internal package.

---

## ðŸ’¡ Why This Matters

Traditional LLMs hallucinate and lack context. RAG solves this by:

- **Grounding answers in real document content**
- **Providing citations for transparency**
- **Optimizing costs by choosing appropriate models**
- **Supporting realâ€‘time UX with streaming**

DocuMind AI implements this in a **professional, productionâ€‘ready** manner.

---

## ðŸ“¦ Core Features

- **Embeddings**
  - Generate vector representations for text
  - Batched embedding support to manage rate limits
- **Vector Retrieval**
  - Qdrant integration with metadata filters
  - Score thresholding for quality
- **LLM Integration**
  - Streaming and nonâ€‘streaming OpenAI responses
  - Complexityâ€‘based model selection (cheap vs highâ€‘quality)
- **Prompt System**
  - Versioned templates
  - Citation formatting and extraction
- **Orchestration**
  - Endâ€‘toâ€‘end RAG pipeline with performance measurement
- **Logging**
  - Structured logs via `pino`
  - Environmentâ€‘driven log levels

---

## ðŸ“Œ Installation

```bash
# Clone the repo
git clone https://github.com/datadave22/documind-ai.git

cd documind-ai/packages/ai

npm install

OPENAI_API_KEY=your_openai_api_key
QDRANT_URL=http://localhost:6333
LOG_LEVEL=info

packages/ai/
â”œâ”€ dist/                     # Compiled output
â”œâ”€ src/
â”‚  â”œâ”€ embeddings.ts          # Embedding generation
â”‚  â”œâ”€ retrieval.ts           # Vector search & Qdrant
â”‚  â”œâ”€ llm.ts                 # OpenAI LLM orchestration
â”‚  â”œâ”€ logger.ts              # Structured logging
â”‚  â”œâ”€ prompts/
â”‚  â”‚  â”œâ”€ qa.ts               # Q&A prompt templates
â”‚  â”‚  â””â”€ versions.ts         # Prompt versioning
â”‚  â””â”€ index.ts               # RAG pipeline orchestration
â”œâ”€ tsconfig.json             # Compiler config
â”œâ”€ package.json              # npm package + scripts
â”œâ”€ .gitignore


Run Query
const response = await streamChat({
  question: "What is RAG?",
  userId: "user_123",
  onToken: (token) => console.log(token)
});

console.log(response);

Question
   â†“
[Embedding Generation]
   â†“
[Vector Retrieval (Qdrant)]
   â†“
[Prompt Construction]
   â†“
[LLM Generation (Streaming)]
   â†“
[Citations + Response]


[1.0.0]
